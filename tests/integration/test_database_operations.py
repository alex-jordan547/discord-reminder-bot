"""
Tests d'int√©gration pour la base de donn√©es.

Ce module teste l'int√©gration compl√®te de la base de donn√©es :
- Op√©rations concurrentes sur la base de donn√©es
- Transactions et rollbacks
- Coh√©rence des donn√©es entre tables
- Performance des requ√™tes complexes
"""

import asyncio
import pytest
import time
from datetime import datetime, timedelta
from threading import Thread
from unittest.mock import patch
from peewee import fn

from models.database_models import Event, Guild, User, Reaction, ReminderLog
from persistence.database import get_database
from tests.fixtures.fixture_manager import FixtureManager

# Import conditionnel pour √©viter les erreurs
try:
    from utils.concurrency_sqlite import SQLiteConcurrency
except ImportError:
    SQLiteConcurrency = None


class TestDatabaseIntegration:
    """Tests d'int√©gration pour les op√©rations de base de donn√©es."""

    @pytest.fixture
    def setup_database_environment(self, temp_database):
        """Pr√©pare l'environnement de base de donn√©es pour les tests."""
        fixture_manager = FixtureManager(temp_database)
        """Pr√©pare l'environnement de base de donn√©es pour les tests."""
        # Cr√©er des donn√©es de test
        guild = fixture_manager.create_guild()
        users = [fixture_manager.create_user() for _ in range(5)]
        events = [fixture_manager.create_event(guild=guild) for _ in range(3)]
        
        return {
            "guild": guild,
            "users": users,
            "events": events,
            "database": temp_database
        }

    @pytest.mark.asyncio
    async def test_concurrent_database_operations(self, setup_database_environment):
        """Test les op√©rations concurrentes sur la base de donn√©es."""
        env = setup_database_environment
        
        results = []
        
        def create_reactions_batch(event, users_subset, batch_id):
            """Cr√©er un lot de r√©actions de mani√®re concurrente."""
            try:
                for i, user in enumerate(users_subset):
                    reaction = Reaction.create(
                        event=event,
                        user=user,
                        emoji=["‚úÖ", "‚ùå", "ü§î"][i % 3],
                        added_at=datetime.now()
                    )
                results.append(f"batch_{batch_id}_success")
                return True
            except Exception as e:
                results.append(f"batch_{batch_id}_error: {str(e)}")
                return False
        
        # Lancer plusieurs threads simultan√©es
        threads = []
        for i in range(3):
            thread = Thread(
                target=create_reactions_batch,
                args=(env["events"][0], env["users"][i:i+2], i)
            )
            threads.append(thread)
            thread.start()
        
        # Attendre la completion
        for thread in threads:
            thread.join()
        
        # V√©rifier les r√©sultats
        success_count = len([r for r in results if "success" in r])
        assert success_count >= 2, "Au moins 2 batches devraient r√©ussir"
        
        # V√©rifier l'int√©grit√© des donn√©es
        total_reactions = Reaction.select().where(Reaction.event == env["events"][0]).count()
        assert total_reactions >= 4, "Au moins 4 r√©actions devraient √™tre cr√©√©es"

    @pytest.mark.asyncio
    async def test_transaction_rollback(self, setup_database_environment):
        """Test les transactions et rollbacks."""
        env = setup_database_environment
        
        initial_event_count = Event.select().count()
        initial_reaction_count = Reaction.select().count()
        
        try:
            with get_database().atomic():
                # Cr√©er un nouvel √©v√©nement
                new_event = Event.create(
                    message_id=999999999,
                    channel_id=888888888,
                    guild=env["guild"],
                    title="Test Transaction",
                    interval_minutes=60.0
                )
                
                # Cr√©er quelques r√©actions
                for user in env["users"][:2]:
                    Reaction.create(
                        event=new_event,
                        user=user,
                        emoji="‚úÖ",
                        added_at=datetime.now()
                    )
                
                # Forcer une erreur pour d√©clencher rollback
                raise Exception("Erreur forc√©e pour test rollback")
                
        except Exception:
            # Exception attendue
            pass
        
        # V√©rifier que rien n'a √©t√© persist√© (rollback effectu√©)
        final_event_count = Event.select().count()
        final_reaction_count = Reaction.select().count()
        
        assert final_event_count == initial_event_count, "Aucun nouvel √©v√©nement ne devrait √™tre persist√©"
        assert final_reaction_count == initial_reaction_count, "Aucune nouvelle r√©action ne devrait √™tre persist√©e"

    @pytest.mark.asyncio
    async def test_data_consistency_across_tables(self, setup_database_environment):
        """Test la coh√©rence des donn√©es entre tables."""
        env = setup_database_environment
        
        # Cr√©er des donn√©es li√©es entre tables
        event = env["events"][0]
        
        # Ajouter des r√©actions
        reactions = []
        for user in env["users"]:
            reaction = Reaction.create(
                event=event,
                user=user,
                emoji="‚úÖ",
                added_at=datetime.now()
            )
            reactions.append(reaction)
        
        # Ajouter des logs de rappels
        reminder_logs = []
        for i in range(3):
            log = ReminderLog.create(
                event=event,
                sent_at=datetime.now() - timedelta(hours=i),
                recipient_count=len(env["users"]),
                success=True
            )
            reminder_logs.append(log)
        
        # V√©rifier la coh√©rence des relations
        # 1. Toutes les r√©actions pointent vers l'√©v√©nement correct
        for reaction in reactions:
            assert reaction.event.id == event.id
            assert reaction.user.id in [u.id for u in env["users"]]
        
        # 2. Tous les logs pointent vers l'√©v√©nement correct  
        for log in reminder_logs:
            assert log.event.id == event.id
        
        # 3. Suppression en cascade
        user_to_delete = env["users"][0]
        reactions_count = Reaction.select().where(
            (Reaction.user_id == user_to_delete.id) & (Reaction.event_id == event.id)
        ).count()
        
        # Supprimer l'utilisateur
        user_to_delete.delete_instance()
        
        # V√©rifier que les r√©actions de cet utilisateur sont supprim√©es
        remaining_reactions_count = Reaction.select().where(Reaction.event == event).count()
        expected_remaining = len(env["users"]) - 1
        
        assert remaining_reactions_count == expected_remaining, "Les r√©actions de l'utilisateur supprim√© devraient √™tre supprim√©es"

    @pytest.mark.asyncio
    async def test_complex_query_performance(self, setup_database_environment):
        """Test les performances des requ√™tes complexes."""
        env = setup_database_environment
        
        # Cr√©er plus de donn√©es pour le test de performance
        additional_events = []
        for i in range(20):
            event = Event.create(
                message_id=700000 + i,
                channel_id=800000 + i,
                guild=env["guild"],
                title=f"Performance Test Event {i}",
                interval_minutes=60.0 + (i * 15),
                is_paused=i % 3 == 0  # Varier l'√©tat de pause
            )
            additional_events.append(event)
            
            # Ajouter des r√©actions pour chaque √©v√©nement
            for j, user in enumerate(env["users"]):
                if (i + j) % 2 == 0:  # Varier les r√©actions
                    Reaction.create(
                        event=event,
                        user=user,
                        emoji=["‚úÖ", "‚ùå", "ü§î"][j % 3],
                        added_at=datetime.now() - timedelta(minutes=i*10)
                    )
        
        # Test 1: Requ√™te complexe avec jointures
        start_time = time.time()
        
        complex_query_results = list(
            Event.select(Event, Guild)
            .join(Guild)
            .where(
                (Event.is_paused == False) & 
                (Event.interval_minutes < 300)
            )
            .order_by(Event.interval_minutes)
        )
        
        query1_duration = time.time() - start_time
        
        assert len(complex_query_results) > 0, "La requ√™te complexe devrait retourner des r√©sultats"
        assert query1_duration < 1.0, f"La requ√™te complexe devrait √™tre rapide (dur√©e: {query1_duration:.3f}s)"
        
        # Test 2: Requ√™te d'agr√©gation
        start_time = time.time()
        
        aggregation_results = (
            Reaction.select(
                Reaction.event,
                Reaction.emoji,
                fn.COUNT(Reaction.id_).alias('reaction_count')
            )
            .group_by(Reaction.event, Reaction.emoji)
            .having(fn.COUNT(Reaction.id_) > 1)
        )
        
        aggregation_list = list(aggregation_results)
        query2_duration = time.time() - start_time
        
        assert query2_duration < 1.0, f"La requ√™te d'agr√©gation devrait √™tre rapide (dur√©e: {query2_duration:.3f}s)"
        
        # Test 3: Requ√™te avec sous-requ√™te
        start_time = time.time()
        
        events_with_reactions = list(
            Event.select()
            .where(
                Event.id_.in_(
                    Reaction.select(Reaction.event).distinct()
                )
            )
        )
        
        query3_duration = time.time() - start_time
        
        assert len(events_with_reactions) > 0, "Il devrait y avoir des √©v√©nements avec r√©actions"
        assert query3_duration < 1.0, f"La sous-requ√™te devrait √™tre rapide (dur√©e: {query3_duration:.3f}s)"

    @pytest.mark.asyncio
    async def test_database_connection_resilience(self, setup_database_environment):
        """Test la r√©silience des connexions √† la base de donn√©es."""
        env = setup_database_environment
        
        # Test 1: Reconnexion apr√®s fermeture
        db = get_database()
        
        # Fermer la connexion
        if not db.is_closed():
            db.close()
        
        # Tenter une op√©ration qui devrait rouvrir la connexion
        try:
            event_count = Event.select().count()
            assert event_count >= 0, "L'op√©ration devrait r√©ussir apr√®s reconnexion"
        except Exception as e:
            pytest.fail(f"La reconnexion automatique devrait fonctionner: {e}")
        
        # Test 2: Gestion des timeouts
        with patch('peewee.SqliteDatabase.execute_sql') as mock_execute:
            # Simuler un timeout
            mock_execute.side_effect = TimeoutError("Database timeout")
            
            try:
                Event.select().count()
            except TimeoutError:
                # Le timeout devrait √™tre g√©r√© gracieusement
                pass
            except Exception as e:
                pytest.fail(f"Les timeouts devraient √™tre g√©r√©s gracieusement: {e}")

    @pytest.mark.asyncio
    async def test_concurrent_schema_operations(self, setup_database_environment):
        """Test les op√©rations concurrentes sur le sch√©ma."""
        env = setup_database_environment
        
        # Simuler des op√©rations concurrentes qui pourraient affecter le sch√©ma
        results = []
        
        def perform_schema_operation(operation_id):
            """Effectuer une op√©ration qui pourrait affecter le sch√©ma."""
            try:
                # Cr√©er des index dynamiques (simulation)
                with get_database().atomic():
                    # Op√©ration qui n√©cessite un verrou sur la base
                    events = list(Event.select().limit(10))
                    
                    for event in events:
                        # Mise √† jour qui pourrait cr√©er des conflits
                        Event.update(
                            last_reminder=datetime.now()
                        ).where(
                            Event.id_ == event.id
                        ).execute()
                
                results.append(f"operation_{operation_id}_success")
                return True
                
            except Exception as e:
                results.append(f"operation_{operation_id}_error: {str(e)}")
                return False
        
        # Lancer plusieurs op√©rations concurrentes
        threads = []
        for i in range(3):
            thread = Thread(target=perform_schema_operation, args=(i,))
            threads.append(thread)
            thread.start()
        
        # Attendre completion
        for thread in threads:
            thread.join()
        
        # Au moins une op√©ration devrait r√©ussir
        success_count = len([r for r in results if "success" in r])
        assert success_count >= 1, "Au moins une op√©ration concurrente devrait r√©ussir"